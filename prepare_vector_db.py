from langchain.text_splitter import RecursiveCharacterTextSplitter
# from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader
from langchain_community.vectorstores import FAISS
# from langchain_openai import OpenAIEmbeddings
# from google import genai
from langchain_google_genai import GoogleGenerativeAIEmbeddings
import os
from dotenv import load_dotenv

load_dotenv()

import getpass
import os

# Example text
text = ''' ChÃ o má»«ng cÃ¡c báº¡n Ä‘áº¿n vá»›i MÃ¬ AI - nÆ¡i chÃºng ta khÃ¡m phÃ¡ tháº¿ giá»›i cá»§a trÃ­ tuá»‡ nhÃ¢n táº¡o! Trong video hÃ´m nay, chÃºng ta sáº½ Ä‘Ã o sÃ¢u vÃ o á»©ng dá»¥ng má»›i vÃ  Ä‘á»™c Ä‘Ã¡o cá»§a Langchain - má»™t cÃ´ng nghá»‡ tiÃªn tiáº¿n Ä‘Æ°a trÃ­ tuá»‡ nhÃ¢n táº¡o lÃªn má»™t táº§m cao má»›i.

ğŸ¤– Langchain khÃ´ng chá»‰ lÃ  má»™t há»‡ thá»‘ng thÃ´ng thÆ°á»ng, mÃ  cÃ²n lÃ  má»™t bÆ°á»›c Ä‘á»™t phÃ¡ trong xÃ¢y dá»±ng mÃ´ hÃ¬nh há»i Ä‘Ã¡p ná»™i dung vÄƒn báº£n. ChÃºng ta sáº½ tÃ¬m hiá»ƒu vá» Retrieval Augmented Generation - má»™t ká»¹ thuáº­t máº¡nh máº½ Ä‘áº±ng sau sá»± thÃ nh cÃ´ng cá»§a Langchain.

ğŸŒ Trong video nÃ y, chÃºng ta sáº½:
1ï¸âƒ£ Hiá»ƒu rÃµ hÆ¡n vá» Retrieval Augmented Generation lÃ  gÃ¬ vÃ  lÃ m tháº¿ nÃ o nÃ³ giÃºp cáº£i thiá»‡n kháº£ nÄƒng há»i Ä‘Ã¡p cá»§a mÃ´ hÃ¬nh.
2ï¸âƒ£ KhÃ¡m phÃ¡ cÃ¡ch Langchain tÃ­ch há»£p Retrieval Augmented Generation Ä‘á»ƒ xÃ¢y dá»±ng mÃ´ hÃ¬nh máº¡nh máº½, linh hoáº¡t vÃ  hiá»‡u quáº£.
3ï¸âƒ£ Äá»“ng hÃ nh cÃ¹ng MÃ¬ AI trong viá»‡c thá»­ nghiá»‡m vÃ  Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a Langchain khi Ä‘á»‘i máº·t vá»›i cÃ¡c thÃ¡ch thá»©c há»i Ä‘Ã¡p vÄƒn báº£n.

ğŸ” CÃ¹ng nhau, chÃºng ta sáº½ khÃ¡m phÃ¡ nhá»¯ng á»©ng dá»¥ng thá»±c táº¿ vÃ  tiá»m nÄƒng mÃ  Retrieval Augmented Generation mang láº¡i trong lÄ©nh vá»±c trÃ­ tuá»‡ nhÃ¢n táº¡o. Äá»«ng quÃªn nháº¥n Ä‘Äƒng kÃ½, like vÃ  báº¥m chuÃ´ng Ä‘á»ƒ khÃ´ng bá» lá»¡ nhá»¯ng video thÃº vá»‹ tiáº¿p theo vá» tháº¿ giá»›i cá»§a trÃ­ tuá»‡ nhÃ¢n táº¡o vÃ  cÃ´ng nghá»‡!"

'''
vector_db_path = "./vectorStore"


# Initialize the text splitter
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50
)

# Split the text
chunks = text_splitter.split_text(text)

#Embedding textstexts
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')

embeddings = GoogleGenerativeAIEmbeddings(model = "models/text-embedding-004",google_api_key= GEMINI_API_KEY)
vector = embeddings.embed_query("Hello world!")
print (vector)


# #Save local using faiss
db = FAISS.from_texts(texts = chunks, embedding= embeddings)
db.save_local(vector_db_path)

# # Print the chunks
# for i, chunk in enumerate(chunks):
#     print(f"Chunk {i+1}: {chunk}")